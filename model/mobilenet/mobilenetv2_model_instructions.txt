
================================================================================
MOBILENETV2 MODEL - USAGE INSTRUCTIONS
================================================================================

Model: mobilenetv2_model
Created: 20251224_080243
Architecture: MobileNetV2 Transfer Learning
Input Shape: (128, 128, 3)
Number of Classes: 3
Class Names: ['Angry', 'Sad', 'Surprise']

================================================================================
FILES INCLUDED
================================================================================

1. mobilenetv2_model.keras
   - Full model (recommended for loading)
   - Contains architecture, weights, and optimizer state

2. mobilenetv2_model.weights.h5
   - Model weights only
   - Use with architecture JSON

3. mobilenetv2_model_architecture.json
   - Model structure in JSON format
   - Use with weights file

4. mobilenetv2_model_20251224_080243.keras
   - Versioned copy of the model
   - Keep for backup/comparison

5. mobilenetv2_model_history.json
   - Training history (loss, accuracy per epoch)
   - Includes both Stage 1 and Stage 2 training

6. mobilenetv2_model_class_indices.json
   - Mapping of class names to indices

7. mobilenetv2_model_config.json
   - Model configuration and metadata
   - Includes training strategy info

8. mobilenetv2_model_metrics.json
   - Performance metrics (precision, recall, f1-score)

9. mobilenetv2_model_summary.txt
   - Complete model summary and architecture details

================================================================================
QUICK START - LOADING THE MODEL
================================================================================

Method 1: Load Full Model (Easiest & Recommended)
--------------------------------------------------
from tensorflow.keras.models import load_model
import numpy as np

# Load model
model = load_model('mobilenetv2_model.keras')
print("✅ MobileNetV2 model loaded successfully!")

# Test with dummy input
test_input = np.random.rand(1, 128, 128, 3)
prediction = model.predict(test_input)
print(f"Output shape: {prediction.shape}")


Method 2: Load Architecture + Weights Separately
-------------------------------------------------
import json
from tensorflow.keras.models import model_from_json
from tensorflow.keras.optimizers import Adam

# Load architecture
with open('mobilenetv2_model_architecture.json', 'r') as f:
    model_json = f.read()
model = model_from_json(model_json)

# Load weights
model.load_weights('mobilenetv2_model.weights.h5')

# Compile model
model.compile(
    optimizer=Adam(learning_rate=1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
print("✅ Model loaded and compiled!")


================================================================================
MAKING PREDICTIONS - IMPORTANT: USE MOBILENETV2 PREPROCESSING!
================================================================================

Single Image Prediction:
------------------------
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
import numpy as np

# Load image
img_path = 'path/to/your/image.jpg'
img = image.load_img(img_path, target_size=(128, 128))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)

# IMPORTANT: Use MobileNetV2 preprocessing!
img_array = preprocess_input(img_array)

# Predict
predictions = model.predict(img_array)

# Load class names
import json
with open('mobilenetv2_model_class_indices.json', 'r') as f:
    class_indices = json.load(f)

class_names = list(class_indices.keys())
predicted_class = class_names[np.argmax(predictions[0])]
confidence = np.max(predictions[0])

print(f"Predicted Class: {predicted_class}")
print(f"Confidence: {confidence:.2%}")
print(f"\nAll Probabilities:")
for cls, prob in zip(class_names, predictions[0]):
    print(f"  {cls}: {prob:.2%}")


Batch Prediction:
-----------------
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# Create test generator with MobileNetV2 preprocessing
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_generator = test_datagen.flow_from_directory(
    'path/to/test/folder',
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# Predict
predictions = model.predict(test_generator)
predicted_classes = np.argmax(predictions, axis=1)

# Evaluation
from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(test_generator.classes, predicted_classes))


================================================================================
LOADING MODEL METADATA
================================================================================

Load Configuration:
-------------------
import json

with open('mobilenetv2_model_config.json', 'r') as f:
    config = json.load(f)

print(f"Model Name: {config['model_name']}")
print(f"Architecture: {config['architecture']}")
print(f"Total Parameters: {config['total_params']:,}")
print(f"Trainable Parameters: {config['trainable_params']:,}")
print(f"Training Strategy: {config['training_strategy']}")
print(f"Stage 1 Epochs: {config['stage1_epochs']}")
print(f"Stage 2 Epochs: {config['stage2_epochs']}")
print(f"Best Val Accuracy: {config['best_val_accuracy']:.4f}")


Load Performance Metrics:
--------------------------
with open('mobilenetv2_model_metrics.json', 'r') as f:
    metrics = json.load(f)

print(f"Overall Accuracy: {metrics['overall_accuracy']:.4f}")
print("\nPer-Class Metrics:")
for cls, metric in metrics['per_class_metrics'].items():
    print(f"\n{cls}:")
    print(f"  Precision: {metric['precision']:.4f}")
    print(f"  Recall: {metric['recall']:.4f}")
    print(f"  F1-Score: {metric['f1_score']:.4f}")
    print(f"  Support: {metric['support']}")


Load Training History:
-----------------------
with open('mobilenetv2_model_history.json', 'r') as f:
    history = json.load(f)

# Plot training curves
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.plot(history['accuracy'], label='Train Accuracy')
plt.plot(history['val_accuracy'], label='Val Accuracy')
plt.title('MobileNetV2 Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(history['loss'], label='Train Loss')
plt.plot(history['val_loss'], label='Val Loss')
plt.title('MobileNetV2 Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()


================================================================================
MODEL INFORMATION
================================================================================

Architecture: MobileNetV2 Transfer Learning
Base Model: MobileNetV2 (pretrained on ImageNet)
Total Parameters: 3,086,659
Trainable Parameters: 2,350,979

Training Configuration:
  - Training Strategy: Two-stage (frozen base + fine-tuning)
  - Stage 1: Train custom head only (frozen base)
  - Stage 2: Fine-tune top 30 layers of base model
  - Optimizer: Adam
  - Initial Learning Rate: 0.0001
  - Fine-tuning Learning Rate: 0.00001
  - Loss Function: categorical_crossentropy
  - Batch Size: 32

Performance:
  - Final Train Accuracy: 0.6969
  - Final Val Accuracy: 0.6994
  - Best Val Accuracy: 0.7002
  - Final Train Loss: 1.7749
  - Final Val Loss: 1.8167

Class Information:
  - Number of Classes: 3
  - Class Names: Angry, Sad, Surprise
  - Class Weights: {class_weights}

Dataset:
  - Training Samples: 5187
  - Validation Samples: 1294


================================================================================
IMPORTANT NOTES FOR MOBILENETV2
================================================================================

⚠️ CRITICAL: Always use MobileNetV2 preprocessing!
   from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
   
   This is DIFFERENT from standard normalization (divide by 255).
   MobileNetV2 expects inputs in range [-1, 1].

1. Image Preprocessing:
   - Always resize images to (128, 128)
   - MUST use preprocess_input from mobilenet_v2
   - Use RGB format (3 channels)
   - DO NOT manually normalize to [0, 1]

2. Model Advantages:
   - Lightweight and fast (suitable for mobile/edge devices)
   - Fewer parameters than ResNet50
   - Good accuracy with efficient computation
   - Ideal for resource-constrained environments

3. Batch Processing:
   - Use ImageDataGenerator with preprocessing_function=preprocess_input
   - Set appropriate batch_size based on your memory

4. Model Evaluation:
   - Always evaluate on a separate test set
   - Check confusion matrix to identify problem classes
   - Monitor confidence scores for predictions

5. Fine-tuning Tips:
   - Already fine-tuned with two-stage approach
   - If retraining: start with very small learning rate (1e-6)
   - Monitor validation loss carefully to avoid overfitting


================================================================================
TROUBLESHOOTING
================================================================================

Q: Model predictions are random/incorrect
A: Make sure you're using MobileNetV2 preprocess_input, NOT standard normalization!
   Wrong: img_array / 255.0
   Correct: preprocess_input(img_array)

Q: Model fails to load
A: Ensure compatible TensorFlow/Keras version.
   Try: pip install tensorflow==2.15.0

Q: Different results each time
A: Set random seeds for reproducibility:
   import numpy as np
   import tensorflow as tf
   np.random.seed(42)
   tf.random.set_seed(42)

Q: Out of memory errors
A: Reduce batch_size when making predictions
   Process images one at a time if necessary

Q: Lower accuracy than expected
A: Verify you're using the correct preprocessing
   Check that images are RGB (not BGR)
   Ensure input size is (128, 128)


================================================================================
COMPARISON WITH OTHER MODELS
================================================================================

MobileNetV2 vs ResNet50:
- ✅ Faster inference time
- ✅ Smaller model size
- ✅ Lower memory footprint
- ✅ Better for mobile/edge deployment
- ⚠️ Slightly lower accuracy (trade-off)

MobileNetV2 vs Custom CNN:
- ✅ Better feature extraction (pretrained)
- ✅ Higher accuracy
- ✅ Faster training (transfer learning)
- ⚠️ Larger model size
- ⚠️ Requires specific preprocessing


================================================================================
CONTACT & SUPPORT
================================================================================

For questions or issues:
- Check model summary: mobilenetv2_model_summary.txt
- Review training history: mobilenetv2_model_history.json
- Examine model config: mobilenetv2_model_config.json

Model created on: 20251224_080243
Architecture: MobileNetV2 Transfer Learning for Emotion Recognition
Task: Multi-class Classification (3 classes)
Training Strategy: Two-stage fine-tuning

================================================================================
